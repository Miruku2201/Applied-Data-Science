{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data Science/AI Engineer  \\nTIEN PHAT BUI  0962980173  | buitienphat2462002 @gmail.com  \\nhttps://www.linkedin.com/in/tien -phat -bui-ba3421222 / \\nhttps://github.com/ShynBui / \\nGo Vap district , Ho Chi Minh city  \\nEducation  \\nBACHELOR OF INFORMATION TECHNOLO GY(Expected 05/2024)  – Ho Chi Minh City Open University – 97 Vo Van Tan, Ward \\n6, District 3, Ho Chi Minh City  \\nGPA: 3.76/4.00 (Highest in Major)   \\nMajors: Information Technology  \\nRelevant Coursework: Machine Learning, Data Visualization and Communication, Database System s and SQL, Natural Language \\nProcessing, Computer Vision, Deep Learning and Neural Networks  \\n \\nSkills  \\nPython  \\nLibraries  and frameworks : pandas, \\nmatplotlib, numpy , \\nBeutiful Soup4, re, os , scikit -learn, \\nHugging Face, transformers,  PyTorch , \\nPython -Flask, LangChain, NLTK  \\n Big Data  \\nApache Hadoop , PySpark  \\n \\nSQL \\nSoftware: SQLite, MySQL , SQL, \\nPostgreSQL  \\n Power Bi  \\nTools: Power Query , Visualize  \\n \\nC++ \\nLibraries : STL, Boot C++, \\nArmadillo  \\nProjects  \\nLEGAL SEARCH AND RES PONSE PLATFORM  – Group competition project   November  2023 - now  \\n● Provides users with quick access to legal information, delivers reliable answers to legal queries, and enables efficient navi gation \\nthrough legal codes and documents  \\n● Utilizes ReactJS for front -end development, employs Python Flask  for b ack-end functionality, and enhances its capabilities with \\ncomplementary integration tools such as CI/CD (Continuous Integration/Continuous Deployment) and Docker for streamlined \\ndeployment processes, ensuring efficient and reliable operation  \\n● Project manage ment, ensuring a waterfall system development process, data search and preprocessing, training deep learning  \\nmodels based on PhoBERT  and LangChain  for question -answering tasks for answering legal and training another model to classify \\n\"legal definition\" se ntences in legal documents, taking on the role of data designer using MySQL , and visualize the model training \\nprocess for reporting  using matplotlib  \\n● Winning third prize in the Vietnam Student Informatics Olympiad - Open source competition, the project attr acted the jury for its \\ncreativity and was considered to have the most potential. The product is open source code that is being invested in, develope d \\nand raised capital  \\n● The article introduces the project : https://vfossa.vn/tin -tuc/code -heroes -nen-tang -tra-cuu-va-giai-dap-phap -luat-ung-dung -sang -\\ntao-cac-mo-hinh -ngon -ngu-lon-698.html  \\nAN AUTOMATICALLY ANS WERING ENGLIS H AND VIETNAMESE REA DING COMPREHENSION S YSTEM  – Personal \\nProject   June 2021 - January 2022  \\n● Assisting users in automatically answering Vietnamese or English reading comprehension questions by providing the system with  \\na passage of information (provided by the user), from which the system extracts information to answer the user\\'s queries  \\n● Using Hugging Face as a model repository, we employ a BERT -based model for answering English reading comprehension \\nquestions and a PhoBERT -based model for answering Vietnamese reading comprehension questions. Gradio is utilized to design \\nan interactive int erface for user interaction  \\n● Taking on the role of data preparation, I utilize available datasets and scrape data from the web using BeautifulSoup4 . Data \\nprocessing is performed using Python , while model fine -tuning is carried out through the use of Transfo rmers and PyTorch . \\nModel evaluation and visualization of evaluation results are conducted using matplotlib  \\n● The English question -answering model achieved a significant 78% accuracy when applied to multiple -choice questions. The \\nVietnamese question -answering  model also achieved an exact match accuracy of 72%  \\n '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('result_pypdf.txt') as f:\n",
    "    text = f.read()\n",
    "    \n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemma's activation function should be approximate GeLU and not exact GeLU.\n",
      "Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3c8ab7943064839b84ef04cabc8bd32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>Perform named entity recognition on the following text: ['Data Science/AI Engineer  \\n', 'TIEN PHAT BUI  0962980173  | buitienphat2462002 @gmail.com  \\n', 'https://www.linkedin.com/in/tien -phat -bui-ba3421222 / \\n', 'https://github.com/ShynBui / \\n', 'Go Vap district , Ho Chi Minh city  \\n', 'Education  \\n', 'BACHELOR OF INFORMATION TECHNOLO GY(Expected 05/2024)  – Ho Chi Minh City Open University – 97 Vo Van Tan, Ward \\n', '6, District 3, Ho Chi Minh City  \\n', 'GPA: 3.76/4.00 (Highest in Major)   \\n', 'Majors: Information Technology  \\n', 'Relevant Coursework: Machine Learning, Data Visualization and Communication, Database System s and SQL, Natural Language \\n', 'Processing, Computer Vision, Deep Learning and Neural Networks  \\n', ' \\n', 'Skills  \\n', 'Python  \\n', 'Libraries  and frameworks : pandas, \\n', 'matplotlib, numpy , \\n', 'Beutiful Soup4, re, os , scikit -learn, \\n', 'Hugging Face, transformers,  PyTorch , \\n', 'Python -Flask, LangChain, NLTK  \\n', ' Big Data  \\n', 'Apache Hadoop , PySpark  \\n', ' \\n', 'SQL \\n', 'Software: SQLite, MySQL , SQL, \\n', 'PostgreSQL  \\n', ' Power Bi  \\n', 'Tools: Power Query , Visualize  \\n', ' \\n', 'C++ \\n', 'Libraries : STL, Boot C++, \\n', 'Armadillo  \\n', 'Projects  \\n', 'LEGAL SEARCH AND RES PONSE PLATFORM  – Group competition project   November  2023 - now  \\n', '● Provides users with quick access to legal information, delivers reliable answers to legal queries, and enables efficient navi gation \\n', 'through legal codes and documents  \\n', '● Utilizes ReactJS for front -end development, employs Python Flask  for b ack-end functionality, and enhances its capabilities with \\n', 'complementary integration tools such as CI/CD (Continuous Integration/Continuous Deployment) and Docker for streamlined \\n', 'deployment processes, ensuring efficient and reliable operation  \\n', '● Project manage ment, ensuring a waterfall system development process, data search and preprocessing, training deep learning  \\n', 'models based on PhoBERT  and LangChain  for question -answering tasks for answering legal and training another model to classify \\n', '\"legal definition\" se ntences in legal documents, taking on the role of data designer using MySQL , and visualize the model training \\n', 'process for reporting  using matplotlib  \\n', '● Winning third prize in the Vietnam Student Informatics Olympiad - Open source competition, the project attr acted the jury for its \\n', 'creativity and was considered to have the most potential. The product is open source code that is being invested in, develope d \\n', 'and raised capital  \\n', '● The article introduces the project : https://vfossa.vn/tin -tuc/code -heroes -nen-tang -tra-cuu-va-giai-dap-phap -luat-ung-dung -sang -\\n', 'tao-cac-mo-hinh -ngon -ngu-lon-698.html  \\n', 'AN AUTOMATICALLY ANS WERING ENGLIS H AND VIETNAMESE REA DING COMPREHENSION S YSTEM  – Personal \\n', 'Project   June 2021 - January 2022  \\n', '● Assisting users in automatically answering Vietnamese or English reading comprehension questions by providing the system with  \\n', \"a passage of information (provided by the user), from which the system extracts information to answer the user's queries  \\n\", '● Using Hugging Face as a model repository, we employ a BERT -based model for answering English reading comprehension \\n', 'questions and a PhoBERT -based model for answering Vietnamese reading comprehension questions. Gradio is utilized to design \\n', 'an interactive int erface for user interaction  \\n', '● Taking on the role of data preparation, I utilize available datasets and scrape data from the web using BeautifulSoup4 . Data \\n', 'processing is performed using Python , while model fine -tuning is carried out through the use of Transfo rmers and PyTorch . \\n', 'Model evaluation and visualization of evaluation results are conducted using matplotlib  \\n', '● The English question -answering model achieved a significant 78% accuracy when applied to multiple -choice questions. The \\n', 'Vietnamese question -answering  model also achieved an exact match accuracy of 72%  \\n', ' ']\n",
      "<eos>\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-7b\", cache_dir=\"../cache\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"google/gemma-7b\", device_map=\"auto\", cache_dir=\"../cache\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>What is large language model?\n",
      "\n",
      "A large language model (LLM) is a type of artificial intelligence (AI) model that is trained on a large corpus of text data. These models are used to generate text that is similar to the text in the training data.\n",
      "\n",
      "LLMs are typically trained on a large amount of text data, such as books, articles, or social media posts. The model is then used to generate new text that is similar to the text in the training data.\n",
      "\n",
      "LLMs are used in a variety of applications, including chatbots, language translation, and text summarization. They are also used in the field of natural language processing (NLP) to improve the accuracy of text analysis and understanding.\n",
      "\n",
      "LLMs are a type of deep learning model, which means that they are trained using a deep neural network architecture. This architecture allows the model to learn complex patterns and relationships in the text data, which enables it to generate text that is similar to the text in the training data.\n",
      "\n",
      "LLMs are a powerful tool for text generation and analysis, and they are being used in a variety of applications to improve the accuracy and efficiency of text processing tasks.\n",
      "\n",
      "<h2>What is GPT-3?</h2>\n"
     ]
    }
   ],
   "source": [
    "input_text = f\"What is large language model?\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**input_ids, max_new_tokens=240)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/phit/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to /home/phit/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "#spacy\n",
    "import spacy\n",
    "from spacy.pipeline import EntityRuler\n",
    "from spacy.lang.en import English\n",
    "from spacy.tokens import Doc\n",
    "\n",
    "#gensim\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "\n",
    "#Visualization\n",
    "from spacy import displacy\n",
    "import pyLDAvis.gensim_models\n",
    "from wordcloud import WordCloud\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Data loading/ Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jsonlines\n",
    "\n",
    "#nltk\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download(['stopwords','wordnet'])\n",
    "\n",
    "#warning\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
